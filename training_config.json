{
    "pretrain": {
      "batch_size": 16,
      "learning_rate": 5e-4,
      "num_epochs": 10,
      "warmup_steps": 1000,
      "max_length": 512,
      "save_steps": 1000,
      "eval_steps": 500,
      "logging_steps": 100
    },
    "instruction": {
      "batch_size": 8,
      "learning_rate": 2e-5,
      "num_epochs": 5,
      "warmup_steps": 100,
      "max_length": 1024,
      "save_steps": 500,
      "eval_steps": 250,
      "logging_steps": 50
    },
    "rlhf": {
      "batch_size": 4,
      "learning_rate": 1e-6,
      "num_episodes": 1000,
      "ppo_epochs": 4,
      "mini_batch_size": 4,
      "cliprange": 0.2,
      "vf_coef": 0.1,
      "ent_coef": 0.01,
      "save_steps": 100,
      "logging_steps": 10
    },
    "data_sources": {
      "pretrain": {
        "wikipedia": {
          "enabled": true,
          "limit": 20000,
          "weight": 0.4
        },
        "news": {
          "enabled": true,
          "limit": 10000,
          "weight": 0.3
        },
        "ecommerce": {
          "enabled": true,
          "weight": 0.3
        }
      },
      "instruction": {
        "belle": {
          "enabled": true,
          "limit": 10000,
          "weight": 0.4
        },
        "alpaca": {
          "enabled": true,
          "limit": 10000,
          "weight": 0.3
        },
        "ecommerce": {
          "enabled": true,
          "weight": 0.3
        }
      }
    },
    "model_config": {
      "model_size": "0.6B",
      "vocab_size": 151936,
      "num_experts": 8,
      "num_experts_per_tok": 2,
      "max_position_embeddings": 4096
    },
    "training_strategy": {
      "gradient_checkpointing": true,
      "mixed_precision": true,
      "gradient_accumulation_steps": 1,
      "dataloader_num_workers": 4,
      "pin_memory": true
    }
  }